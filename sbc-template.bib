@inproceedings{ribeiro2016should,
  title        = {``{W}hy should {I} trust you?'': {E}xplaining the predictions of any classifier},
  author       = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle    = {Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages        = {1135--1144},
  year         = {2016}
}

@article{Ribeiro_Singh_Guestrin_2018,
  title        = {Anchors: High-Precision Model-Agnostic Explanations},
  volume       = {32},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/11491},
  DOI          = {10.1609/aaai.v32i1.11491},
  abstractNote = { &lt;p&gt; We introduce a novel model-agnostic system that explains the behavior of complex models with high-precision rules called anchors,
  representing local,
  &quot;sufficient&quot; conditions for predictions. We propose an algorithm to efficiently compute these explanations for any black-box model with high-probability guarantees. We demonstrate the flexibility of anchors by explaining a myriad of different models for different domains and tasks. In a user study,
  we show that anchors enable users to predict how a model would behave on unseen instances with less effort and higher precision,
  as compared to existing linear explanations or no explanations. &lt;/p&gt; },
  number       = {1},
  journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author       = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  year         = {2018},
  month        = {Apr.}
}

@article{lundberg2017unified,
  title        = {A unified approach to interpreting model predictions},
  author       = {Lundberg, Scott M and Lee, Su-In},
  journal      = {Advances in neural information processing systems},
  volume       = {30},
  year         = {2017}
}
